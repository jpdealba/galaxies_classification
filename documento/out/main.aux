\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{spanish}{}
\citation{colab_notebook}
\citation{accuracy_metric}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introducción}{7}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Definición del Proyecto}{7}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Objetivo}{7}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Expectativas}{7}{subsection.2.2}\protected@file@percent }
\citation{precision_metric}
\citation{recall_metric}
\citation{fscore_metric}
\citation{roc_metric}
\citation{kaggle_dataset}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Métricas de Evaluación}{8}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Exploración de Datos}{8}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Descripción de Datos}{8}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Identificadores y Metadatos del Survey}{9}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Posición y Movimiento}{9}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Magnitudes Fotométricas}{9}{subsubsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}Parámetros Morfológicos}{9}{subsubsection.3.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.5}Parámetros de Stokes}{9}{subsubsection.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.6}Revisión de Calidad de Datos}{10}{subsubsection.3.1.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Información general del dataset obtenida con df.info(). Se confirma la estructura completa con 4,000,000 entradas, 51 columnas sin valores nulos, y un uso de memoria de 1.5+ GB. Los tipos de datos incluyen enteros (int64), flotantes (float64) y objetos (object) para la variable objetivo.}}{11}{figure.1}\protected@file@percent }
\newlabel{fig:info_dataset}{{1}{11}{Información general del dataset obtenida con df.info(). Se confirma la estructura completa con 4,000,000 entradas, 51 columnas sin valores nulos, y un uso de memoria de 1.5+ GB. Los tipos de datos incluyen enteros (int64), flotantes (float64) y objetos (object) para la variable objetivo}{figure.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.7}Estadísticas Descriptivas}{11}{subsubsection.3.1.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Estadísticas descriptivas - Ejemplo: Variables de identificación, posición y magnitudes PSF. Se observa que todas las variables tienen el conteo completo de 4,000,000 observaciones, confirmando la ausencia de valores faltantes.}}{12}{figure.2}\protected@file@percent }
\newlabel{fig:describe1}{{2}{12}{Estadísticas descriptivas - Ejemplo: Variables de identificación, posición y magnitudes PSF. Se observa que todas las variables tienen el conteo completo de 4,000,000 observaciones, confirmando la ausencia de valores faltantes}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Distribución de Datos}{12}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Balance de Clases}{12}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Distribución de las clases en el dataset. Se observa que las variables tienen el conteo completo de 4,000,000 observaciones.}}{12}{figure.3}\protected@file@percent }
\newlabel{fig:count}{{3}{12}{Distribución de las clases en el dataset. Se observa que las variables tienen el conteo completo de 4,000,000 observaciones}{figure.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Análisis de Distribuciones por Variable}{13}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Histogramas con curvas de densidad KDE de variables con distribuciones relativamente normales. Las curvas de densidad (generadas con \texttt  {sns.histplot} y \texttt  {kde=True}) proporcionan una representación suave de la distribución, facilitando la identificación de patrones y modas. Se muestran ejemplos representativos de las 52 columnas del dataset.}}{13}{figure.4}\protected@file@percent }
\newlabel{fig:variables_normales}{{4}{13}{Histogramas con curvas de densidad KDE de variables con distribuciones relativamente normales. Las curvas de densidad (generadas con \texttt {sns.histplot} y \texttt {kde=True}) proporcionan una representación suave de la distribución, facilitando la identificación de patrones y modas. Se muestran ejemplos representativos de las 52 columnas del dataset}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Histogramas con curvas de densidad KDE de variables con distribuciones altamente sesgadas. Las curvas de densidad revelan claramente la concentración de valores cerca de cero y las colas extremas. La estimación por kernel (KDE) ayuda a visualizar mejor la forma de estas distribuciones asimétricas. Debido a la cantidad de columnas (52), se muestran ejemplos representativos.}}{13}{figure.5}\protected@file@percent }
\newlabel{fig:variables_sesgadas}{{5}{13}{Histogramas con curvas de densidad KDE de variables con distribuciones altamente sesgadas. Las curvas de densidad revelan claramente la concentración de valores cerca de cero y las colas extremas. La estimación por kernel (KDE) ayuda a visualizar mejor la forma de estas distribuciones asimétricas. Debido a la cantidad de columnas (52), se muestran ejemplos representativos}{figure.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Identificación de Valores Atípicos}{14}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Boxplots de magnitudes fotométricas mostrando la presencia de valores atípicos. Estos outliers representan objetos astronómicos reales (muy brillantes o muy débiles) y contienen información valiosa para la clasificación.}}{14}{figure.6}\protected@file@percent }
\newlabel{fig:boxplot1}{{6}{14}{Boxplots de magnitudes fotométricas mostrando la presencia de valores atípicos. Estos outliers representan objetos astronómicos reales (muy brillantes o muy débiles) y contienen información valiosa para la clasificación}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Boxplots de parámetros de Stokes y variables de movimiento. Se observa la concentración extrema de valores cerca de cero y la presencia de outliers exagerados, especialmente en los parámetros q\_* y u\_*.}}{15}{figure.7}\protected@file@percent }
\newlabel{fig:boxplot2}{{7}{15}{Boxplots de parámetros de Stokes y variables de movimiento. Se observa la concentración extrema de valores cerca de cero y la presencia de outliers exagerados, especialmente en los parámetros q\_* y u\_*}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Boxplots de parámetros morfológicos (relaciones de ejes y algunos histogramas adicionales). Las variables expAB\_* muestran distribuciones más controladas, mientras que otras variables presentan comportamientos diversos. Debido a las 52 columnas del dataset, se presentan ejemplos representativos.}}{15}{figure.8}\protected@file@percent }
\newlabel{fig:boxplot3}{{8}{15}{Boxplots de parámetros morfológicos (relaciones de ejes y algunos histogramas adicionales). Las variables expAB\_* muestran distribuciones más controladas, mientras que otras variables presentan comportamientos diversos. Debido a las 52 columnas del dataset, se presentan ejemplos representativos}{figure.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Correlación de Datos}{15}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Correlación con la Variable Objetivo}{15}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Correlación de todas las variables con la variable objetivo (type\_numeric). Las variables con correlaciones más altas (en valor absoluto) son las más discriminativas para la clasificación.}}{16}{figure.9}\protected@file@percent }
\newlabel{fig:correlacion_target}{{9}{16}{Correlación de todas las variables con la variable objetivo (type\_numeric). Las variables con correlaciones más altas (en valor absoluto) son las más discriminativas para la clasificación}{figure.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Matriz de Correlación Completa}{16}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Matriz de correlación entre todas las variables del dataset. Los colores más intensos indican correlaciones más fuertes (positivas en azul, negativas en amarillo). Se observan bloques de alta correlación entre variables del mismo tipo (e.g., magnitudes en diferentes filtros, radios en diferentes bandas).}}{17}{figure.10}\protected@file@percent }
\newlabel{fig:matriz_correlacion}{{10}{17}{Matriz de correlación entre todas las variables del dataset. Los colores más intensos indican correlaciones más fuertes (positivas en azul, negativas en amarillo). Se observan bloques de alta correlación entre variables del mismo tipo (e.g., magnitudes en diferentes filtros, radios en diferentes bandas)}{figure.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Exportación para Análisis Detallado}{17}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Preparación de Datos}{18}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Limpieza}{18}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Verificación de Valores Faltantes y Duplicados}{18}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Eliminación de Variables No Informativas}{18}{subsubsection.4.1.2}\protected@file@percent }
\citation{chi2_test}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Codificación de la Variable Objetivo}{19}{subsubsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Selección de Variables}{19}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Criterios de Selección}{19}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Variables Seleccionadas}{19}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Validación Estadística de la Selección}{20}{subsubsection.4.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Estadísticos chi-cuadrado para las variables seleccionadas. Valores más altos indican mayor asociación con la variable objetivo. Todas las variables muestran estadísticos muy elevados, confirmando su relevancia discriminativa.}}{20}{figure.11}\protected@file@percent }
\newlabel{fig:chi2}{{11}{20}{Estadísticos chi-cuadrado para las variables seleccionadas. Valores más altos indican mayor asociación con la variable objetivo. Todas las variables muestran estadísticos muy elevados, confirmando su relevancia discriminativa}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces P-valores asociados a la prueba chi-cuadrado para cada variable. Todos los p-valores son prácticamente cero, rechazando la hipótesis nula de independencia.}}{21}{figure.12}\protected@file@percent }
\newlabel{fig:pvalue}{{12}{21}{P-valores asociados a la prueba chi-cuadrado para cada variable. Todos los p-valores son prácticamente cero, rechazando la hipótesis nula de independencia}{figure.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Preprocesado (Logaritmo, RobustScaler)}{21}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Arquitectura del Pipeline de Preprocesado}{21}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Diagrama del pipeline de preprocesado implementado. Se muestra la arquitectura del ColumnTransformer con dos ramas de procesamiento: una para variables que requieren transformación logarítmica y otra para variables estándar.}}{22}{figure.13}\protected@file@percent }
\newlabel{fig:pipeline_preprocesado}{{13}{22}{Diagrama del pipeline de preprocesado implementado. Se muestra la arquitectura del ColumnTransformer con dos ramas de procesamiento: una para variables que requieren transformación logarítmica y otra para variables estándar}{figure.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Transformación}{22}{subsubsection.4.3.2}\protected@file@percent }
\citation{sklearn_robustscaler}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Ejemplo de la efectividad de la transformación logarítmica en variables con distribuciones altamente sesgadas. Se muestra la comparación entre las distribuciones originales (izquierda) y después de aplicar log1p (derecha) para modelFlux\_i y modelFlux\_z. La transformación convierte distribuciones extremadamente sesgadas en distribuciones más simétricas y manejables para los algoritmos de machine learning.}}{23}{figure.14}\protected@file@percent }
\newlabel{fig:transformacion_logaritmica}{{14}{23}{Ejemplo de la efectividad de la transformación logarítmica en variables con distribuciones altamente sesgadas. Se muestra la comparación entre las distribuciones originales (izquierda) y después de aplicar log1p (derecha) para modelFlux\_i y modelFlux\_z. La transformación convierte distribuciones extremadamente sesgadas en distribuciones más simétricas y manejables para los algoritmos de machine learning}{figure.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Selección de RobustScaler}{23}{subsubsection.4.3.3}\protected@file@percent }
\citation{sklearn_simpleimputer}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}Estrategia de Imputación}{24}{subsubsection.4.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.5}Optimización de Rendimiento}{24}{subsubsection.4.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Modelo de Machine Learning}{25}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Regresión Logística}{25}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Pipeline completo para Regresión Logística, integrando el preprocesado especializado para datos astronómicos con el clasificador optimizado.}}{25}{figure.15}\protected@file@percent }
\newlabel{fig:pipeline_lr}{{15}{25}{Pipeline completo para Regresión Logística, integrando el preprocesado especializado para datos astronómicos con el clasificador optimizado}{figure.15}{}}
\citation{sklearn_lr}
\@writefile{toc}{\contentsline {section}{\numberline {6}Resultados}{27}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Comparación de Técnicas de Validación}{27}{subsection.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Comparación entre train\_test\_split (80\%-20\%) y validación cruzada de 5 folds. Ambas técnicas muestran resultados consistentes, confirmando la estabilidad del modelo.}}{27}{figure.16}\protected@file@percent }
\newlabel{fig:validacion}{{16}{27}{Comparación entre train\_test\_split (80\%-20\%) y validación cruzada de 5 folds. Ambas técnicas muestran resultados consistentes, confirmando la estabilidad del modelo}{figure.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Métricas de Evaluación del Modelo}{27}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Optimización de Hiperparámetros}{28}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Implementación del Modelo Final}{28}{subsection.6.4}\protected@file@percent }
\citation{cohen_kappa}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Evaluación en Dataset de Test}{29}{subsection.6.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Matriz de confusión del modelo final en el dataset de test. Se muestran las predicciones para 1 millón de objetos astronómicos clasificados como STAR (0) o GALAXY (1).}}{29}{figure.17}\protected@file@percent }
\newlabel{fig:matriz_confusion}{{17}{29}{Matriz de confusión del modelo final en el dataset de test. Se muestran las predicciones para 1 millón de objetos astronómicos clasificados como STAR (0) o GALAXY (1)}{figure.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Índice Kappa de Cohen}{29}{subsection.6.6}\protected@file@percent }
\citation{roc_analysis}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Resultado del índice kappa de Cohen para el modelo final. El valor obtenido demuestra una relación significativa entre las predicciones del modelo y las etiquetas verdaderas.}}{30}{figure.18}\protected@file@percent }
\newlabel{fig:kappa}{{18}{30}{Resultado del índice kappa de Cohen para el modelo final. El valor obtenido demuestra una relación significativa entre las predicciones del modelo y las etiquetas verdaderas}{figure.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Análisis de la Curva ROC}{30}{subsection.6.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Curva ROC del modelo final mostrando un AUC de 0.99. La curva se aproxima al punto óptimo (0,1), indicando un rendimiento excelente. La línea punteada representa el rendimiento aleatorio (AUC = 0.50).}}{30}{figure.19}\protected@file@percent }
\newlabel{fig:roc_curve}{{19}{30}{Curva ROC del modelo final mostrando un AUC de 0.99. La curva se aproxima al punto óptimo (0,1), indicando un rendimiento excelente. La línea punteada representa el rendimiento aleatorio (AUC = 0.50)}{figure.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusión}{32}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Conclusiones del Proyecto}{32}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Problemas Enfrentados y Soluciones}{32}{subsection.7.2}\protected@file@percent }
\bibcite{sklearn_lr}{1}
\bibcite{kaggle_dataset}{2}
\bibcite{colab_notebook}{3}
\bibcite{sklearn_robustscaler}{4}
\bibcite{sklearn_simpleimputer}{5}
\bibcite{accuracy_metric}{6}
\bibcite{recall_metric}{7}
\bibcite{fscore_metric}{8}
\bibcite{precision_metric}{9}
\bibcite{roc_metric}{10}
\bibcite{cohen_kappa}{11}
\bibcite{roc_analysis}{12}
\bibcite{chi2_test}{13}
\@writefile{toc}{\contentsline {section}{Bibliografía}{34}{subsection.7.2}\protected@file@percent }
\gdef \@abspage@last{34}
